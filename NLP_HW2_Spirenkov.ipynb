{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cEcdEOmYEeoV",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import requests\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import pymorphy2\n",
    "\n",
    "import requests\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from gensim.models.phrases import Phrases\n",
    "\n",
    "\n",
    "from gensim.models import LdaMulticore #, LdaModel\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mSsrM4q-Q2u"
   },
   "source": [
    "# Modules of Functions for preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOtCWzOP9887"
   },
   "source": [
    "### Save data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "x3GGc8MTJIzD",
    "outputId": "4450ce95-368d-4cb2-9c9b-5986d268da1f",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./tales.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\users\\scott mars\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\scott mars\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\scott mars\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\users\\scott mars\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\scott mars\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\users\\scott mars\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tales.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./tales.csv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_6JYcKu989F"
   },
   "source": [
    "### Separate tales\n",
    "delete classes, make lowercase and separate on 3 groups:\n",
    "\n",
    "0. adult tales\n",
    "1. children tales\n",
    "2. all ages tales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z9nPzsOWgNb-"
   },
   "outputs": [],
   "source": [
    "def tales_separator(df, category):\n",
    "    df = df[df['Tale,Label'].str.endswith(category)].copy()\n",
    "    df['Tale,Label'] = df['Tale,Label'].str[:-4].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EtTMDuov989I"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m adult_tales \u001b[38;5;241m=\u001b[39m tales_separator(\u001b[43mdf\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m children_tales \u001b[38;5;241m=\u001b[39m tales_separator(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m all_ages_tales \u001b[38;5;241m=\u001b[39m tales_separator(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "adult_tales = tales_separator(df, '0')\n",
    "children_tales = tales_separator(df, '1')\n",
    "all_ages_tales = tales_separator(df, '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1LikW-C989J"
   },
   "source": [
    "### Merge tales with target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d3ufkWGg989K"
   },
   "outputs": [],
   "source": [
    "def merge_topics(df_dict, col, target):\n",
    "    result_df = pd.DataFrame(columns = [col, target])\n",
    "    for key in df_dict.keys():\n",
    "        df_dict[key][target] = key\n",
    "        result_df = pd.concat([result_df, df_dict[key]])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvLooM-2989M",
    "outputId": "7c98a67c-60c1-489a-d2a5-ddb0a5fab6be"
   },
   "outputs": [],
   "source": [
    "df_dict = {0 : children_tales,\n",
    "           1 : adult_tales,\n",
    "           2 : all_ages_tales}\n",
    "\n",
    "df_raw = merge_topics(df_dict, 'Tale,Label', 'target')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC4cjsWl989N"
   },
   "source": [
    "### Clearing lines with Regular Expressions\n",
    "\n",
    "1. \"3-ий1\" case - [0-9]{1,}-[0-9,а-я]{1,}\n",
    "2. numbers - [0-9]\n",
    "3. extra symbols - [-,.?:;!»«/\\—)(#$%^&*№%'\"]\n",
    "4. spaces greater than 2 - [ ]{1,}\n",
    "5. start / end spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06zMplW0gNfs"
   },
   "outputs": [],
   "source": [
    "def regular_cleaning(df, col):\n",
    "    temp = 0\n",
    "    for row in df.index:\n",
    "        temp = re.sub(r\"[0-9]{1,}-[0-9,а-я]{1,}\", \"\", df[col][row])\n",
    "        temp = re.sub(r\"[0-9]\", \" \", temp)\n",
    "        temp = re.sub(r'\"', \" \", temp)\n",
    "        temp = re.sub(r\"[-,.?:;!»«/\\–)(#$%^&*№%']\", \" \", temp)\n",
    "        temp = re.sub(r\"[ ]{1,}\", \" \", temp)\n",
    "        if temp.endswith(\" \"):\n",
    "            temp = temp[:-1]\n",
    "        if temp.startswith(\" \"):\n",
    "            temp = temp[1:]\n",
    "        df[col][row] = temp\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9VLciqe989P"
   },
   "outputs": [],
   "source": [
    "# children_tales = regular_cleaning(children_tales, 'Tale,Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zxp_1jne989Q"
   },
   "source": [
    "### Lemmatize lines (1) with pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CTKshSD989Q"
   },
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "def lemmatize_str(sent, myStemObj):\n",
    "    lemmat_list = []\n",
    "    try:\n",
    "        lemmas = myStemObj.lemmatize(sent)\n",
    "        for i in lemmas:\n",
    "            if i.isalpha():\n",
    "                lemmat_list.append(i)\n",
    "        return lemmat_list\n",
    "    except BrokenPipeError:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmrXpsS4989R"
   },
   "outputs": [],
   "source": [
    "# children_tales['Tale,Label'] = children_tales['Tale,Label'].apply(lambda x: lemmatize_str(x, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VO60fcKK989S"
   },
   "source": [
    "### Lemmatize lines (2) with pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_W5FvgAm989S"
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmat_pymorph(sent, morph):\n",
    "    sent = sent.split()\n",
    "    return [morph.parse(word)[0].normal_form for word in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEqGqI0G989T"
   },
   "outputs": [],
   "source": [
    "# children_tales['Tale,Label'] = children_tales['Tale,Label'].apply(lambda x: lemmat_pymorph(x, morph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRY6zqPk989T"
   },
   "source": [
    "### Remove Stop words\n",
    "create big stop words dictionary and write clearing stop words function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGw1y0hW989U",
    "outputId": "92562e33-d4e0-4e87-8c14-8a2e67cecbaa",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# download stop words list from github\n",
    "r = requests.get('https://raw.githubusercontent.com/stopwords-iso/stopwords-ru/master/stopwords-ru.txt')\n",
    "stop_list = r.text.split()\n",
    "\n",
    "# merge NLTK & github stop words lists\n",
    "stop_words_dict = stopwords.words('russian')\n",
    "print(\"NLTK Stop words dictionary length:\", len(stop_words_dict), type(stop_words_dict))\n",
    "stop_words_dict.extend(stop_list)\n",
    "stop_words_dict = list(set(stop_words_dict))\n",
    "stop_words_dict.remove('не')\n",
    "stop_words_dict.append('—')\n",
    "\n",
    "print(\"Final Stop words dictionary length:\", len(stop_words_dict), type(stop_words_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGEcapwG989U"
   },
   "outputs": [],
   "source": [
    "def stop_words_remover(corpus, stopWords, col):\n",
    "    for num_sent in corpus.index:\n",
    "        temp_dialog_list = corpus[col].loc[num_sent]\n",
    "        temp_dialog_list = [word for word in temp_dialog_list if not word in stopWords]\n",
    "        corpus[col].loc[num_sent] = temp_dialog_list\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSs1Rkzm989V"
   },
   "outputs": [],
   "source": [
    "# children_tales = stop_words_remover(children_tales, stop_words_dict, 'Tale,Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnlqN7gl989V"
   },
   "source": [
    "### Make Bigrams & Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4iU03KB989V"
   },
   "outputs": [],
   "source": [
    "def n_gram_maker(df, col, min_count = 4, threshold = 10):\n",
    "    min_count = min_count - 1\n",
    "    tmp_dict_list = list(df[col])\n",
    "    ngrams = Phrases(tmp_dict_list, min_count = min_count, threshold = threshold)\n",
    "    list(ngrams[tmp_dict_list])\n",
    "    return list(ngrams[tmp_dict_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJ7bCYC4989W"
   },
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zJu_xIg989W"
   },
   "outputs": [],
   "source": [
    "# bigrams_children_tales = children_tales.copy()\n",
    "# bigrams_children_tales['Tale,Label'] = n_gram_maker(children_tales, 'Tale,Label', 8, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VkF57cF989W"
   },
   "source": [
    "### Merge \"НЕ\" + next_word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlISTqyh989W"
   },
   "outputs": [],
   "source": [
    "def HE_merge(wd_list):\n",
    "    ind_list = []\n",
    "    for i, wd in enumerate(wd_list):\n",
    "        if wd == 'не' and i != (len(wd_list) - 1):\n",
    "            wd_list[i] = wd_list[i] + '_' + wd_list[i+1]\n",
    "            ind_list.append(wd_list[i+1])\n",
    "    return list(filter(lambda x: x not in ind_list, wd_list)) if ind_list else wd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0RvnZuU989X"
   },
   "outputs": [],
   "source": [
    "# children_tales['Tale,Label'] = children_tales['Tale,Label'].apply(lambda x: HE_merge(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8e_cfYT989X"
   },
   "source": [
    "### Remove \"НЕ\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvJC_HO1989X"
   },
   "outputs": [],
   "source": [
    "def HE_remove(wd_list):\n",
    "    return list(filter(lambda x: x != 'не', wd_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SYkSqbJ989X"
   },
   "outputs": [],
   "source": [
    "# children_tales['Tale,Label'] = children_tales['Tale,Label'].apply(lambda x: HE_remove(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-6saugY989Y"
   },
   "source": [
    "### Remove word(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DIqaiPD989Y"
   },
   "outputs": [],
   "source": [
    "def wds_remover(line, wds_list):\n",
    "    return list(filter(lambda x: x not in wds_list, line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zN7K-crs989Y"
   },
   "outputs": [],
   "source": [
    "# children_tales['Tale,Label'] = children_tales['Tale,Label'].apply(lambda line: wds_remover(line, wds_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJicUErUBEbr"
   },
   "source": [
    "# Functions for preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88i3o3GA989Y"
   },
   "source": [
    "### prepoc_1\n",
    "### * reg_exp + pymorphy + stop_words + HE_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9G9eLHW989Z"
   },
   "outputs": [],
   "source": [
    "def prepoc_1(data, col, stop_words_dict):\n",
    "    data = regular_cleaning(data, col)\n",
    "    data[col] = data[col].apply(lambda x: lemmat_pymorph(x, morph))\n",
    "    data = stop_words_remover(data, stop_words_dict, col)\n",
    "    data[col] = data[col].apply(lambda x: HE_remove(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmqD3DWG989Z"
   },
   "source": [
    "### prepoc_2\n",
    "### * reg_exp + mystem + stop_words + HE_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYoyuPD3989Z"
   },
   "outputs": [],
   "source": [
    "def prepoc_2(data, col, stop_words_dict):\n",
    "    data = regular_cleaning(data, col)\n",
    "    data[col] = data[col].apply(lambda x: lemmatize_str(x, m))\n",
    "    data = stop_words_remover(data, stop_words_dict, col)\n",
    "    data[col] = data[col].apply(lambda x: HE_remove(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ1rNiT4989Z"
   },
   "source": [
    "### prepoc_3\n",
    "### reg_exp + mystem + stop_words + HE_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Q98ppvK989Z"
   },
   "outputs": [],
   "source": [
    "def prepoc_3(data, col, stop_words_dict):\n",
    "    data = regular_cleaning(data, col)\n",
    "    data[col] = data[col].apply(lambda x: lemmatize_str(x, m))\n",
    "    data = stop_words_remover(data, stop_words_dict, col)\n",
    "    data[col] = data[col].apply(lambda x: HE_merge(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPoTa0c5989a"
   },
   "source": [
    "### prepoc_4\n",
    "### reg_exp + mystem + stop_words + bigram + HE_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vu7_Mtie989a"
   },
   "outputs": [],
   "source": [
    "def prepoc_4(data, col, stop_words_dict, bgm_freq = 8, threshold = 7):\n",
    "    data = regular_cleaning(data, col)\n",
    "    data[col] = data[col].apply(lambda x: lemmatize_str(x, m))\n",
    "    data = stop_words_remover(data, stop_words_dict, col)\n",
    "    data[col] = n_gram_maker(data, col, bgm_freq, threshold)\n",
    "    data[col] = data[col].apply(lambda x: HE_remove(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ93zi4S989a"
   },
   "source": [
    "### prepoc_5\n",
    "### reg_exp + mystem + stop_words + trigram + HE_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLJWO9dc989a"
   },
   "outputs": [],
   "source": [
    "def prepoc_5(data, col, stop_words_dict, bgm_freq = 8, tgm_freq = 5, threshold = 7):\n",
    "    data = regular_cleaning(data, col)\n",
    "    data[col] = data[col].apply(lambda x: lemmatize_str(x, m))\n",
    "    data = stop_words_remover(data, stop_words_dict, col)\n",
    "    data[col] = n_gram_maker(data, col, bgm_freq, threshold)\n",
    "    data[col] = n_gram_maker(data, col, tgm_freq, threshold)\n",
    "    data[col] = data[col].apply(lambda x: HE_remove(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZOZJPGF989a"
   },
   "source": [
    "### prepoc_6 EXTRA\n",
    "удаляем все слова кроме НЕ и:\n",
    "* прилагательное (A)\n",
    "* наречие (ADV)\n",
    "* местоимение-прилагательное(APRO)\n",
    "* часть композита - сложного слова (COM)\n",
    "* существительное (S)\n",
    "### reg_exp + mystem + stop_words + part_of_speech_filt + bigram + HE_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Efnryq0k989b"
   },
   "source": [
    "# Preprocess data & Best model after different preprocessing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9l8S6Uf989b"
   },
   "source": [
    "Copy main dataset 5 times for 5 dif preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6gGxp6Z989b"
   },
   "outputs": [],
   "source": [
    "df_raw_1 = df_raw.copy()\n",
    "df_raw_2 = df_raw.copy()\n",
    "df_raw_3 = df_raw.copy()\n",
    "df_raw_4 = df_raw.copy()\n",
    "df_raw_5 = df_raw.copy()\n",
    "col = 'Tale,Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLBExbth989b",
    "outputId": "b0f80857-33e5-42c1-9baf-c04b6503c818"
   },
   "outputs": [],
   "source": [
    "df_prep_1 = prepoc_1(df_raw_1, col, stop_words_dict)\n",
    "print(*df_raw_1['Tale,Label'].iloc[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilxKZGtL989b",
    "outputId": "c704fdc8-cd0a-41e4-89d8-34e76e521805"
   },
   "outputs": [],
   "source": [
    "df_prep_2 = prepoc_2(df_raw_2, col, stop_words_dict)\n",
    "print(*df_raw_2['Tale,Label'].iloc[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VA904wFk989c",
    "outputId": "04503342-af13-4527-e378-d601f849c388"
   },
   "outputs": [],
   "source": [
    "df_prep_3 = prepoc_3(df_raw_3, col, stop_words_dict)\n",
    "print(*df_raw_3['Tale,Label'].iloc[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ek4sbX-989c",
    "outputId": "5ccc1f29-fdc6-4fd3-9fd0-75a24b33e821"
   },
   "outputs": [],
   "source": [
    "df_prep_4 = prepoc_4(df_raw_4, col, stop_words_dict, bgm_freq = 8, threshold = 7)\n",
    "print(*df_raw_4['Tale,Label'].iloc[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8DLMdWl989c",
    "outputId": "843a1222-44ef-4c34-9ccc-985b38df2d01",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_prep_5 = prepoc_5(df_raw_5, col, stop_words_dict, bgm_freq = 8, tgm_freq = 5, threshold = 7)\n",
    "print(*df_raw_5['Tale,Label'].iloc[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnWViswR989c"
   },
   "source": [
    "Run 5 LDA default models with dif preprocessing algorithms to find the best one.\n",
    "\n",
    "number of topics (n_topics) = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCp3WVgk989d",
    "outputId": "0e39f487-b54f-4a2d-c207-0da7308dd4c7"
   },
   "outputs": [],
   "source": [
    "docs = [df_prep_1, df_prep_2, df_prep_3, df_prep_4, df_prep_5]\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    doc_list = list(doc[col])\n",
    "    n_topics = 3\n",
    "    n_words = 12\n",
    "    \n",
    "    dct = corpora.Dictionary(doc_list)\n",
    "    corpus = [dct.doc2bow(line) for line in doc_list]\n",
    "\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                         id2word=dct,\n",
    "                         num_topics=n_topics,\n",
    "                         passes=10,\n",
    "                         random_state=2022\n",
    "                        )\n",
    "    \n",
    "    print(i + 1, 'preproc.')\n",
    "    print('Perplexity: ', lda_model.log_perplexity(corpus))\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=doc_list, dictionary=dct, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('Coherence Score: ', coherence_lda, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DAsZFxC989d"
   },
   "source": [
    "Best preproc on LdaMulticore model. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-iHKUzd989d"
   },
   "outputs": [],
   "source": [
    "def get_LDA_res(doc, col, n_words = 12):\n",
    "    doc_list = list(doc[col])\n",
    "    n_topics = 3\n",
    "\n",
    "    dct = corpora.Dictionary(doc_list)\n",
    "    corpus = [dct.doc2bow(line) for line in doc_list]\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                         id2word=dct,\n",
    "                         num_topics= n_topics,\n",
    "                         passes=10,\n",
    "                         random_state=2022\n",
    "                        )\n",
    "\n",
    "    print(i + 1, 'preproc.')\n",
    "    print('Perplexity: ', lda_model.log_perplexity(corpus))\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=doc_list, dictionary=dct, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('Coherence Score: ', coherence_lda, '\\n')\n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nt4fBoSU989e",
    "outputId": "a76226fa-12a2-4385-c1be-0190b14e4e80"
   },
   "outputs": [],
   "source": [
    "doc = df_prep_1\n",
    "\n",
    "lda_model_prep_1 = get_LDA_res(doc, col)\n",
    "dct = corpora.Dictionary(list(doc[col]))\n",
    "corpus = [dct.doc2bow(line) for line in doc_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Heagjplz989e"
   },
   "source": [
    "#### First good SCORE\n",
    "default LdaMulticore with 1 preprocessing techniques\n",
    "* Perplexity:  -9.151746406174441\n",
    "* Coherence Score:  0.4056843395969147 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hibJi54x989e"
   },
   "source": [
    "# Find Best Hyperparameters with GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BnXflrT989e"
   },
   "source": [
    "Links for tuning parameters:\n",
    "1. https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "2. https://stackoverflow.com/questions/65014553/how-to-tune-the-parameters-for-gensim-ldamulticore-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bzazNLL989e"
   },
   "source": [
    "Function for learning models with determined params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIU0HrzT989e"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(doc, col, i,n, ch_size_val, pw_topics_val, decay_val, n_words = 12, mod = False):\n",
    "    \n",
    "    doc_list = list(doc[col])\n",
    "    n_topics = 3\n",
    "    \n",
    "    dct = corpora.Dictionary(doc_list)\n",
    "    corpus = [dct.doc2bow(line) for line in doc_list]\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dct,\n",
    "                                           num_topics=n_topics,\n",
    "                                           random_state=2022,\n",
    "                                           passes=10,\n",
    "                                           chunksize=ch_size_val,\n",
    "                                           per_word_topics = pw_topics_val,\n",
    "                                           decay = decay_val)\n",
    "    \n",
    "    print(f'{i} from {n}. ch_size_val = {ch_size_val}, pw_topics_val = {pw_topics_val}, decay_val = {decay_val}.')\n",
    "    print('Perplexity: ', lda_model.log_perplexity(corpus))\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=doc_list, dictionary=dct, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('Coherence Score: ', coherence_lda, '\\n')\n",
    "    \n",
    "    if mod: return lda_model\n",
    "    return coherence_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anh73pUL989f"
   },
   "source": [
    "naive GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxVU-ZaN989f",
    "outputId": "0d47bab3-5874-4c94-c22d-40ed3afd80f5"
   },
   "outputs": [],
   "source": [
    "doc = df_prep_1\n",
    "col = 'Tale,Label'\n",
    "\n",
    "per_word_topics = [True, False]\n",
    "chunksize = [100, 500, 1000, 2000, 5000]\n",
    "decay = [0.5, 1]\n",
    "\n",
    "i, n = 1, len(per_word_topics) * len(chunksize) * len(decay)\n",
    "\n",
    "for ch_size_val in chunksize:\n",
    "    for pw_topics_val in per_word_topics:\n",
    "        for decay_val in decay:\n",
    "            _ = compute_coherence_values(doc = doc, col = col, i = i, n = n, \n",
    "                                         ch_size_val = ch_size_val, pw_topics_val = pw_topics_val, \n",
    "                                         decay_val = decay_val, n_words = 12)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMiuLIic989f"
   },
   "source": [
    "best params are: ch_size_val = 100, pw_topics_val = False, decay_val = 0.5.\n",
    "* Perplexity:  -9.095068910308957\n",
    "* Coherence Score:  0.45228439636094936 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIDeLkcp989f"
   },
   "source": [
    "reproducing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrUH2edP989g"
   },
   "outputs": [],
   "source": [
    "dct = corpora.Dictionary(doc_list)\n",
    "corpus = [dct.doc2bow(line) for line in doc_list]\n",
    "\n",
    "lda_viz = gensimvis.prepare(lda_model_1, corpus, dct)\n",
    "lda_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUTjKpXG989g"
   },
   "outputs": [],
   "source": [
    "wds_list = [']', '[', 'пьер', 'андрей', \n",
    "            'наташа', 'ростов', 'нибыть', 'чичиков', \n",
    "            'марья', 'анна', 'всякий', 'николай', \n",
    "            'de', 'соня', 'иванович', 'вильям', \n",
    "            'ежели', 'борис', 'андреевич', 'денисов', \n",
    "            'иван', 'анатоль', 'ах'] \n",
    "\n",
    "df_prep_1[col] = df_prep_1[col].apply(lambda line: wds_remover(line, wds_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdudoZHa989g",
    "outputId": "9eaf3820-efaa-4eb0-b933-d67a3bdb4de6"
   },
   "outputs": [],
   "source": [
    "doc = df_prep_1\n",
    "list(doc[col])\n",
    "col = 'Tale,Label'\n",
    "\n",
    "ch_size_val = 100\n",
    "pw_topics_val = False\n",
    "decay_val = 0.5\n",
    "\n",
    "lda_best_model = compute_coherence_values(doc = doc, col = col, i = 1, n = 1, \n",
    "                                         ch_size_val = ch_size_val, pw_topics_val = pw_topics_val, \n",
    "                                         decay_val = decay_val, n_words = 12, mod = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5XDbtgF989g"
   },
   "source": [
    "Plot graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xq38nQpH989g",
    "outputId": "553d6b8f-d151-4da1-9019-6f50c0447522"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "dct = corpora.Dictionary(list(doc[col]))\n",
    "corpus = [dct.doc2bow(line) for line in doc_list]\n",
    "\n",
    "lda_viz = gensimvis.prepare(lda_best_model, corpus, dct)\n",
    "lda_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aojyWlJ2989h",
    "outputId": "bd8174bc-3b05-4854-b685-6d6b7ac1185b"
   },
   "outputs": [],
   "source": [
    "# save prep data\n",
    "df_prep_1.to_csv('preproc_1_data.csv', index=False)\n",
    "\n",
    "# save best model after prep\n",
    "lda_model_prep_1\n",
    "\n",
    "# save best model after GS\n",
    "lda_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oz_KdBwn989h"
   },
   "source": [
    "#### BEST SCORE\n",
    "3 from 20. ch_size_val = 100, pw_topics_val = False, decay_val = 0.5.\n",
    "* Perplexity:  -9.095068910308957\n",
    "* Coherence Score:  0.45228439636094936 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zv5Ex66989h"
   },
   "source": [
    "# Выводы по получившимся топикам:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGJNGvFT989h"
   },
   "source": [
    "### Группа 1: бытовые сказки\n",
    "* Муж, ребенок, мама, парень, девушка, подруга, секс\n",
    "\n",
    "### Группа 2: нейтральные сказки\n",
    "* Действующие лица - князь, бог, граф, княжна, государь, генерал, офицер, солдат, графиня\n",
    "* Специфичные глаголы - глядеть\n",
    "* Еще характерные слова - гора, лошадь, улыбка, письмо\n",
    "\n",
    "### Группа 3: сказки про бизнес\n",
    "* Деньги, власть, компания, бизнес, группировка, клиент, покупатель\n",
    "* Сюзерен, вассал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCa2LqdB989i"
   },
   "source": [
    "# Поиск доминирующей темы в каждом тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKLiE_nc989i"
   },
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoNBOjjX989i",
    "outputId": "0cb6416f-2220-47b0-eab2-9e2bb149b663"
   },
   "outputs": [],
   "source": [
    "domin_df = format_topics_sentences(lda_best_model, corpus, list(df_prep_1[col]))\n",
    "domin_df.head()\n",
    "\n",
    "domin_df['target'] = df_prep_1['target']\n",
    "domin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BW8YtLw989j"
   },
   "outputs": [],
   "source": [
    "def vals_for_accuracy_topics(df, topic_num):\n",
    "    dominant_df = df[df['target'] == topic_num]\n",
    "    df_0 = dominant_df[dominant_df['Dominant_Topic'] == 0].shape[0]\n",
    "    df_1 = dominant_df[dominant_df['Dominant_Topic'] == 1].shape[0]\n",
    "    df_2 = dominant_df[dominant_df['Dominant_Topic'] == 2].shape[0]\n",
    "    dominant_cnt = max(df_0, df_1, df_2)\n",
    "    print(f'total docs: {dominant_df.shape[0]}')\n",
    "    print(f'docs with dominant topic: {dominant_cnt} \\n')\n",
    "    return dominant_df.shape[0], dominant_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pK0k2a7c989j",
    "outputId": "ff7827f0-4f5a-432d-da64-f457b87f9e76"
   },
   "outputs": [],
   "source": [
    "all_vals, domain_vals = 0, 0\n",
    "\n",
    "for i in range(3):\n",
    "    tmp_all, tmp_dom = vals_for_accuracy_topics(domin_df, i)\n",
    "    all_vals += tmp_all\n",
    "    domain_vals += tmp_dom\n",
    "\n",
    "acc = domain_vals / all_vals\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Kuf3gFO989j"
   },
   "source": [
    "### Варианты по улучшению:\n",
    "1. Построить график распределения слов и удалить самые частые \n",
    "2. Удалить имена и отчества\n",
    "3. Оставить только существительные, прилагательные, наречия, композитарные слова\n",
    "4. Опробовать BigARTM модель"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Topic modeling (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
